machineLearning
===============

此处内容参考《机器学习实战（图灵程序设计丛书72）》以及周志华的《机器学习》两本书。

# K-临近算法

K-临近算法通过测量不同特征值直接的距离进行分类。

优点：精度高、对异常值不敏感、无数据输入假定。
缺点：计算复杂度高、空间复杂度高。
适用数据范围：数值型、标称型。

一般流程：
1. 收集数据：任何形式。
2. 准备数据：距离计算所需要的数据，最好是结构化的数据格式。
3. 分析数据：可以使用任何方法。
4. 训练算法：此步骤不适用于此算法。
5. 测试算法：计算错误率。
6. 使用算法：首先需要输入样本数据和结构化的输出结果，然后运行K临近算法判定输入数据分别属于哪个分类，最后应用对计算出的分类执行后续的处理。

程序伪码：
1. 计算已知类别数据集中的点与当前点之间的距离；
2. 按照距离递增依次排序；
3. 选取与当前点距离最小的k个点；
4. 确定前k个点所在类别的出现频率；
5. 返回前k个点出现频率最高的类别作为当前点的预测分类。

# 决策树

决策树的一个重要任务是为了理解数据中蕴含的知识信息，因此决策树可以使用不熟悉的数据经济和，并从中提取一系列规则。

优点：计算复杂度不高、输出结果易于理解、对于中间值的缺失不敏感、可以处理不相干的特征数据。
缺点：可能会参数过度匹配问题。
适用数据范围：数值型、标称型。

一般流程：
1. 收集数据：任何形式。
2. 准备数据：树构造算法只适用于标称型数据，因此数值型数据必须离散化。
3. 分析数据：可以使用任何方法，构造树完成之后，我们应该检查图形是否符合预期。
4. 训练算法：构造树的数据结构。
5. 测试算法：使用经验树计算错误率。
6. 使用算法：此步骤可以适用于任何监督学习算法，而使用决策树可以更好地理解数据的内在含义。
